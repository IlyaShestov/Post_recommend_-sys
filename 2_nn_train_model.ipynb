{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2659363f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nПредобработка данных ( талица пост обработана заранее нейросетью) и обучение модели\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Предобработка данных ( талица пост обработана заранее нейросетью) и обучение модели\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ceeee557",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import numpy as np\n",
    "\n",
    "from category_encoders.count import CountEncoder\n",
    "from category_encoders.one_hot import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import re\n",
    "import string\n",
    "from sklearn.decomposition import PCA\n",
    "np.random.seed(74)\n",
    "from catboost import CatBoostClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64f952a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(y,X,y_tr, X_tr, model):\n",
    "    \"\"\"\n",
    "    Получает на выход данные терйна и теста, а также обученыю модель.\n",
    "    Функция возвращает Precision, Recall, f1, ROC-AUC на трейне и на тесте.\n",
    "    А так же кол-во положительных передположений (лайков) на трейне и тесте.\n",
    "    \"\"\"\n",
    "    from sklearn.metrics import log_loss, roc_auc_score\n",
    "    \n",
    "    from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "    precision_train = precision_score(y_tr, model.predict(X_tr),  average='macro')\n",
    "    recall_train = recall_score(y_tr, model.predict(X_tr),  average='macro')\n",
    "    f1_train= f1_score(y_tr, model.predict(X_tr),  average='macro')\n",
    "    roc_train = roc_auc_score(y_tr, model.predict(X_tr),  average='macro')\n",
    "    \n",
    "    precision = precision_score(y, model.predict(X),  average='macro')\n",
    "    recall = recall_score(y, model.predict(X),  average='macro')\n",
    "    f1= f1_score(y, model.predict(X),  average='macro')\n",
    "    roc = roc_auc_score(y, model.predict(X), average='macro')\n",
    "    \n",
    "    result_1_train = sum(model.predict(X_tr))\n",
    "    result_1_test = sum(model.predict(X))\n",
    "    \n",
    "    return [[f'precision_tr= {precision_train:.4f}, recall_tr= {recall_train:.4f}, f1_tr= {f1_train:.4f}, ROC-AUC_tr= {roc_train:.4f}'],\n",
    "            [f'precision= {precision:.4f}, recall= {recall:.4f}, f1= {f1:.4f}, ROC-AUC= {roc:.4f}'], \n",
    "            [f'На трейне предположили {result_1_train}, на тесте предположили {result_1_test}']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "813512c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_feed(feed):\n",
    "    #предобрабатывает таблицу feed\n",
    "    feed_ = feed.copy()\n",
    "    feed_ = feed_.drop_duplicates()\n",
    "    return feed_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b0ca3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_post(post, n_pca = 20, drop = True, ohe = True,lemma =True):\n",
    "    \"\"\"\n",
    "    Функция получает на вход таблицу пост post.\n",
    "    Опционально проводит OneHotEncoding типов постов,\n",
    "    Лемматизацию текстов, Tf-Idf и накладывает на полученые вектора  PCA\n",
    "    \n",
    "    :n_pca: кол-во изерений в новом пространстве, если 0 не проводит pca b tf-idf\n",
    "    :drop: = True/False дропать ли колонку текст\n",
    "    :ohe: = True/False проводить ли  OneHotEncoding колонки topic\n",
    "    :lemma: =True/False проводить ли лемматизацию\n",
    "       \n",
    "    \"\"\"\n",
    "    post_ = post.copy()\n",
    "    wnl = WordNetLemmatizer()\n",
    "    \n",
    "    if lemma == True:\n",
    "        def preprocessing(line, token=wnl):\n",
    "            line = line.lower()\n",
    "            line = re.sub(r\"[{}]\".format(string.punctuation), \" \", line)\n",
    "            line = line.replace('\\n\\n', ' ').replace('\\n', ' ')\n",
    "            line = ' '.join([token.lemmatize(x) for x in line.split(' ')])\n",
    "            return line\n",
    "    else:\n",
    "        preprocessing = None\n",
    "\n",
    "    #учу OHE_Post\n",
    "    if ohe == True:\n",
    "        one_hot = pd.get_dummies(post_['topic'], prefix='topic', drop_first=True)\n",
    "        post_  = pd.concat((post_.drop(['topic'], axis=1), one_hot), axis=1)\n",
    "        post_transformd = post_\n",
    "    elif ohe == False:\n",
    "        post_transformd = post_.drop(['topic'],axis =1 )\n",
    "    \n",
    "    if n_pca > 0 :\n",
    "        #провожу tf-idf для Post\n",
    "    \n",
    "        tf = TfidfVectorizer(stop_words='english',\n",
    "                             preprocessor=preprocessing, \n",
    "                             min_df = 5) #создаю экземпляр класса\n",
    "        tf_idf_ = tf.fit_transform(post_['text'])#учу класс\n",
    "        tf_idf_ = tf_idf_.toarray() - tf_idf_.mean() #центрируем данные\n",
    "\n",
    "        list_col_pca = [f\"PCA_{nn}\" for nn in range(1,n_pca + 1)] \n",
    "        #ПРовожу PCA для User\n",
    "        pca = PCA(n_components=n_pca,random_state = 74)\n",
    "        #создаю экземплря PCA\n",
    "        PCA_dataset = pca.fit_transform(tf_idf_) #провожу PCA \n",
    "        PCA_dataset = pd.DataFrame(PCA_dataset, columns=list_col_pca,index=post.index)\n",
    "        #Трансформирую Post\n",
    "    \n",
    "        post_transformd = pd.concat((post_transformd, PCA_dataset), axis=1)\n",
    "        if drop == True:\n",
    "            post_transformd = post_transformd.drop(['text'],axis=1) \n",
    "            \n",
    "    \n",
    "    else:\n",
    "        if drop == True:\n",
    "            post_transformd = post_transformd.drop(['text'],axis=1)\n",
    "        \n",
    "    return post_transformd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56bedf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_user_with_drop_fich(user,drop_col = [],ohe_col=[], count_city = True, count_country = True, age_group = 'group', norm = True):\n",
    "    \"\"\"\n",
    "    Функция получает на вход таблицу пост user.\n",
    "    Опционально проводит дропает колонки, проводит OnehotEncoding и CounterEncoding\n",
    "    а так же может раскодировать возвраст по группам \n",
    "    :drop_col:колонки для дропа\n",
    "    :ohe_col: колонки для OnehotEncoding\n",
    "    :count_city: и :count_country: (Bool) проводить ли CounterEncoding по колонкам city и country\n",
    "    :age_group: 'group'/None кодировать ли возвраст\n",
    "    :norm: (Bool) нормализовать ли данные при CounterEncoding\n",
    "    \"\"\"\n",
    "    user_ = user.copy().drop(drop_col, axis=1) #убираю колонки дропа\n",
    "    # Новый столбец с категориями возраста\n",
    "    bins = [0, 18, 30, 60, 120]\n",
    "    \n",
    "    if 'age' not in drop_col and (age_group == 'group'):\n",
    "        user_['age_group'] = pd.cut(user_['age'], bins, labels=['0-17', '18-30', '30-60', '60+'])\n",
    "        user_ = user_.drop(['age'] , axis =1 )\n",
    "    elif 'age' not in drop_col and (age_group == 'count'):\n",
    "        counter_age = CountEncoder(cols=['age'], \n",
    "                            return_df=True,\n",
    "                            normalize=True)\n",
    "        user_ = counter_age.fit_transform(user_)\n",
    "    elif 'age' not in drop_col and (age_group == 'none'):\n",
    "        user_ = user_\n",
    "    \n",
    "    #учу CounterEncoder_User\n",
    "    \n",
    "    if ('city' not in drop_col) and (count_city == True):\n",
    "        counter_user = CountEncoder(cols=['city'], \n",
    "                            return_df=True,\n",
    "                            normalize=norm)\n",
    "        user_ = counter_user.fit_transform(user_)\n",
    "        \n",
    "    if ('country' not in drop_col) and (count_country == True):\n",
    "        counter_country = CountEncoder(cols=['country'], \n",
    "                            return_df=True,\n",
    "                            normalize=norm)\n",
    "        user_ = counter_country.fit_transform(user_)\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "    #OHE_User\n",
    "    for col in ohe_col:\n",
    "        one_hot = pd.get_dummies(user_[col], prefix=col, drop_first=True)\n",
    "        user_ = pd.concat((user_.drop(col, axis=1), one_hot), axis=1)\n",
    "    \n",
    "    \n",
    "    return user_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e3bdcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_df(feed_transformd,user_transformd,post_transformd): #feed user post\n",
    "    \"\"\"\n",
    "    Мерджит три таблицы feed, user, post в одну\n",
    "    \"\"\"\n",
    "    df = pd.merge(feed_transformd.sort_values(by ='timestamp' ),\n",
    "              user_transformd,\n",
    "              on = 'user_id',\n",
    "              how = 'left')\n",
    "    df= pd.merge(df,\n",
    "             post_transformd,\n",
    "             on='post_id',\n",
    "             how ='left')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9deb03f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitter(df):\n",
    "    \"\"\"\n",
    "    Делит сет на трейн и тест 80/20 и выделяет лейблы\n",
    "    Принимает датаверйм\n",
    "    Возвращает \n",
    "    :X_train,y_train данные для обучения и лейблы\n",
    "    :X_test,y_test данные для валидации и лейблы\n",
    "    \"\"\"\n",
    "    train = df.iloc[:-int(df.shape[0]*0.2)].copy()\n",
    "    test = df.iloc[-int(df.shape[0]*0.2):].copy()\n",
    "    \n",
    "    train_id = train[['user_id','post_id']]\n",
    "    test_id = test[['user_id','post_id']] \n",
    "    \n",
    "    #print(f\"Значение 0:: на трейне: {(train.groupby(['target'])['post_id'].count())[0]} на тесте: {(test.groupby(['target'])['post_id'].count())[0]} \")\n",
    "    #print(f\"Значение 1:: на трейне: {(train.groupby(['target'])['post_id'].count())[1]} на тесте: {(test.groupby(['target'])['post_id'].count())[1]}\\n\")\n",
    "    X_train, X_test = train.drop(['target','timestamp','user_id','post_id','action'], axis =1 ),test.drop(['target','timestamp','user_id','post_id','action'], axis =1 )\n",
    "    y_train, y_test = train['target'], test['target']\n",
    "    #print(f'X_train size = {X_train.shape} , X_test size = {X_test.shape} \\n y_train size = {y_train.shape} , y_test size = {y_test.shape}')\n",
    "    \n",
    "    return [X_train,y_train,X_test,y_test,train_id,test_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff4ed43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_features(df):\n",
    "    \"\"\"\n",
    "    Принимает датафрейм\n",
    "    Выделяет из колонки timestamp час, месяц и день недели \n",
    "    Возвращет датафрейм временными фичами\n",
    "    \"\"\"\n",
    "    df_with_data = df.copy()\n",
    "    df_with_data['hour'] =  pd.to_datetime(df_with_data['timestamp']).apply(lambda x: x.hour)\n",
    "    df_with_data['month'] = pd.to_datetime(df_with_data['timestamp']).apply(lambda x: x.month)\n",
    "    df_with_data['dayofweek'] = pd.to_datetime(df_with_data['timestamp']).apply(lambda x: x.dayofweek)\n",
    "    return df_with_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a65c092",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_db_with_drop(user__, \n",
    "                     post__, \n",
    "                     feed__,\n",
    "                     n_pca,\n",
    "                     drop_col_,\n",
    "                     ohe_col_, \n",
    "                     ohe_topic = True,\n",
    "                     count_city = True,\n",
    "                     count_country = True,\n",
    "                     age_group_ = True,\n",
    "                     norm = True):\n",
    "    \"\"\" Функция обедияет в себе вышестоящие функции и принимает необработаные таблицы  feed, user, post.\n",
    "    Аргументы:\n",
    "    :drop_col:колонки для дропа\n",
    "    :ohe_col: колонки для OnehotEncoding\n",
    "    :count_city: и :count_country: (Bool) проводить ли CounterEncoding по колонкам city и country\n",
    "    :age_group: 'group'/None кодировать ли возвраст\n",
    "    :norm: (Bool) нормализовать ли данные при CounterEncoding\n",
    "    :n_pca: кол-во изерений в новом пространстве, если 0 не проводит pca b tf-idf\n",
    "    :drop: = True/False дропать ли колонку текст\n",
    "    :ohe: = True/False проводить ли  OneHotEncoding колонки topic\n",
    "    :lemma: =True/False проводить ли лемматизацию\n",
    "    \n",
    "    Возвращет полностью подготоваленные данные для обаботки:\n",
    "    :X_train,y_train данные для обучения и лейблы\n",
    "    :X_test,y_test данные для валидации и лейблы\n",
    "    \"\"\"\n",
    "    \n",
    "    user_transformd_= transform_user_with_drop_fich(user,drop_col = drop_col_,\n",
    "                                                    ohe_col=ohe_col_,\n",
    "                                                    count_city = count_city, \n",
    "                                                    count_country = count_country, \n",
    "                                                    age_group = age_group_)\n",
    "    post_transformd_ = post__\n",
    "    feed_transformd_ = transform_feed(feed__)\n",
    "    \n",
    "    df_ = concat_df(feed_transformd_,user_transformd_,post_transformd_)\n",
    "    #serch_df(df_)\n",
    "    df_ = get_data_features(df_)\n",
    "    \n",
    "    return  splitter(df_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "785e3963",
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_imp(model,X_tr): \n",
    "    \"\"\"\n",
    "    выводит фичи в порядке значимости\n",
    "    принимает:\n",
    "    :model: модель catboost\n",
    "    :X_tr: набот фичей на которых училась модель\n",
    "    \"\"\"\n",
    "    x= {}\n",
    "    for (feature,col) in zip(model.feature_importances_,X_tr.columns):\n",
    "        if  feature>0:\n",
    "            x[col] = feature   \n",
    "    return dict(sorted(x.items(), key=lambda item: item[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccb620d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_proba_sort(model,X_ts,y_ts,sort = True, lim = 30):  #model,X_ts,y_ts\n",
    "    \"\"\"\n",
    "    Получает на вход:\n",
    "    model: обученая модель \n",
    "    :X_ts, y_ts:данные тестовой выборки\n",
    "    :sort:(bool) проводить ли сортировку\n",
    "    :lim: лимит вывода\n",
    "    Возвращает датаферм в формате: таргет, предсказание модели, уверенность модели\n",
    "    \"\"\"\n",
    "    y_predict = pd.DataFrame(model.predict(X_ts), columns=['predict'])\n",
    "    y_predict_proba = pd.DataFrame(model.predict_proba(X_ts), columns=['predict_proba_0','predict_proba_1'] )\n",
    "    df = pd.merge(X_ts.reset_index(),\n",
    "             y_ts.reset_index(),\n",
    "             left_index=True, \n",
    "             right_index=True,\n",
    "             how ='left')\n",
    "    df = pd.merge(df,\n",
    "             y_predict,\n",
    "             left_index=True, \n",
    "             right_index=True,\n",
    "             how ='left')\n",
    "    df = pd.merge(df,\n",
    "             y_predict_proba,\n",
    "             left_index=True, \n",
    "             right_index=True,\n",
    "             how ='left')\n",
    "    if sort == True:\n",
    "        df = df.sort_values(by ='predict_proba_1' ,ascending = False)\n",
    "    \n",
    "    return df[['target','predict','predict_proba_1']].head(lim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea70a20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "post = pd.read_csv('post_pca_2_nn.csv')\n",
    "user = pd.read_csv('user.csv')\n",
    "feed = pd.read_csv('feed50_50_2mil', parse_dates=[\"timestamp\"]).drop(['index'],axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4f725966",
   "metadata": {},
   "outputs": [],
   "source": [
    "#создадим словарь для результатов\n",
    "dict_result = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9abfa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# обрабатываем данные\n",
    "drop_col = []\n",
    "ohe_col=['os','source']#\n",
    "ohe_topic = True # КОДИРУЕМ ЛИ TOPIC\n",
    "count_city = True #кодируем ли счетчиком city\n",
    "count_country = True #кодируем ли country\n",
    "age_group = 'none' #кодируем ли ваозвраст в группы\n",
    "norm = True\n",
    "for pca_num  in [2]: #кол-во PCA в сете\n",
    "    train_test_list = get_db_with_drop(user, post, feed, \n",
    "                                       pca_num ,\n",
    "                                       drop_col,\n",
    "                                       ohe_col,\n",
    "                                       ohe_topic,\n",
    "                                       count_city,\n",
    "                                       count_country,\n",
    "                                       age_group, \n",
    "                                       norm) #[X_train,y_train,X_test,y_test]\n",
    "    X_train , y_train,X_test , y_test = train_test_list[0], train_test_list[1], train_test_list[2], train_test_list[3]\n",
    "    \n",
    "    train_id, test_id =  train_test_list[4],train_test_list[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "89d7735a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7007734ef594b3bbb434d94c2cb0a7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "MetricVisualizer(layout=Layout(align_self='stretch', height='500px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#учим модель\n",
    "#cat boost на трансформированых категориях + PCA 2 на эмбедингай нейросети\n",
    "    \n",
    "for i in [2000]:\n",
    "    \n",
    "    model_Cat_5 = CatBoostClassifier(random_state = 74) \n",
    "    model_Cat_5.set_params(iterations=i,random_state = 74, loss_function='Logloss')\n",
    "    \n",
    "    model_Cat_5.fit(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        \n",
    "        verbose=0,\n",
    "        plot = 1\n",
    "        )\n",
    "    ###eval_set=(X_test, y_test),  \n",
    "    dict_result[f'Cat_boost_cl_f+ NN={pca_num}, i={i}'] = get_score(y_test,X_test, y_train, X_train, model_Cat_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61a14377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Cat_boost_cl_f+ NN=2, i=2000': [['precision_tr= 0.9160, recall_tr= 0.9143, f1_tr= 0.9147, ROC-AUC_tr= 0.9143'],\n",
       "  ['precision= 0.8994, recall= 0.9001, f1= 0.8997, ROC-AUC= 0.9001'],\n",
       "  ['На трейне предположили 746204, на тесте предположили 214498']]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_result  #0.0832534"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8fad257",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_Cat_5.save_model('model_Cat_2000it_(2ml)_with_data_nn',\n",
    "#                         format=\"cbm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d3b18456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'topic_covid': 0.004311929370604576,\n",
       " 'topic_movie': 0.006875304396339395,\n",
       " 'topic_tech': 0.017680787281081165,\n",
       " 'topic_entertainment': 0.01960299766589262,\n",
       " 'topic_politics': 0.04773714260678964,\n",
       " 'topic_sport': 0.0785893492888314,\n",
       " 'dayofweek': 0.09551918736757403,\n",
       " 'PCA_2': 0.11371857196128404,\n",
       " 'month': 0.15909485554952416,\n",
       " 'PCA_1': 0.1681133642870348,\n",
       " 'hour': 0.22300987305683145,\n",
       " 'gender': 4.441391669238436,\n",
       " 'os_iOS': 4.904956627036499,\n",
       " 'source_organic': 4.961367776376124,\n",
       " 'country': 5.565552446163298,\n",
       " 'exp_group': 11.678758806121836,\n",
       " 'age': 27.06136283777829,\n",
       " 'city': 40.452356474453744}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Влияние фичей на предсказание в порядке возрастания\n",
    "feature_imp(model_Cat_5,X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "889071c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>predict</th>\n",
       "      <th>predict_proba_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.736721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.944665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.913136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.996877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.189634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   target  predict  predict_proba_1\n",
       "0       1        1         0.736721\n",
       "1       1        1         0.944665\n",
       "2       1        1         0.913136\n",
       "3       1        1         0.996877\n",
       "4       0        0         0.189634"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#достанем предсказания модели для теста\n",
    "preds = predict_proba_sort(model_Cat_5,X_test, y_test, False, 400000)\n",
    "preds.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d217a2bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>post_id</th>\n",
       "      <th>target</th>\n",
       "      <th>predict</th>\n",
       "      <th>predict_proba_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1600000</th>\n",
       "      <td>115197</td>\n",
       "      <td>5677</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.736721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600001</th>\n",
       "      <td>52361</td>\n",
       "      <td>2040</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.944665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600002</th>\n",
       "      <td>28486</td>\n",
       "      <td>4238</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.913136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600003</th>\n",
       "      <td>135597</td>\n",
       "      <td>210</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.996877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600004</th>\n",
       "      <td>145738</td>\n",
       "      <td>3033</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.189634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600005</th>\n",
       "      <td>132135</td>\n",
       "      <td>1504</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.689930</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         user_id  post_id  target  predict  predict_proba_1\n",
       "index                                                      \n",
       "1600000   115197     5677       1        1         0.736721\n",
       "1600001    52361     2040       1        1         0.944665\n",
       "1600002    28486     4238       1        1         0.913136\n",
       "1600003   135597      210       1        1         0.996877\n",
       "1600004   145738     3033       0        0         0.189634\n",
       "1600005   132135     1504       0        1         0.689930"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#склеим предсказания с id пользователя \n",
    "preds = pd.merge(test_id.reset_index(),\n",
    "                   preds,\n",
    "                   left_index=True, \n",
    "                   right_index=True,\n",
    "                   how ='left').set_index('index')\n",
    "\n",
    "preds.head(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc3eb5f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Средний hitrate@5 по пользователям из теста: 0.817\n"
     ]
    }
   ],
   "source": [
    "# посчитаем  hitrate@5 на тестовой выборке\n",
    "k = 5\n",
    "hitrate = []\n",
    "\n",
    "for user in preds['user_id'].unique():\n",
    "    part = preds[preds['user_id'] == user][:k]\n",
    "    \n",
    "    part['compare'] = part['predict'] == part['target']\n",
    "    a = len(part[part['compare'] == True])\n",
    "    \n",
    "    hitrate_k = a / k\n",
    "    hitrate.append(hitrate_k)\n",
    "    \n",
    "print(f\"Средний hitrate@5 по пользователям из теста: {round(np.mean(hitrate), 3)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
