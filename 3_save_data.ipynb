{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c744384",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Подготовавливаем данные из таблицы POST  для залива в БД и дальнейшей работы модели\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60d1221a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Илья\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import numpy as np\n",
    "import url from url\n",
    "from category_encoders.count import CountEncoder\n",
    "from category_encoders.one_hot import OneHotEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "import re\n",
    "import string\n",
    "from sklearn.decomposition import PCA\n",
    "np.random.seed(74)\n",
    "from catboost import CatBoostClassifier\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.orm import sessionmaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0052b527",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "post = pd.read_csv('post.csv')\n",
    "user = pd.read_csv('user.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2be0dcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_user_with_drop_fich(user,drop_col = [],ohe_col=[], count_city = True, count_country = True, age_group = 'group', norm = True):\n",
    "    \"\"\"\n",
    "    Функция получает на вход таблицу пост user.\n",
    "    Опционально проводит дропает колонки, проводит OnehotEncoding и CounterEncoding\n",
    "    а так же может раскодировать возвраст по группам \n",
    "    :drop_col:колонки для дропа\n",
    "    :ohe_col: колонки для OnehotEncoding\n",
    "    :count_city: и :count_country: (Bool) проводить ли CounterEncoding по колонкам city и country\n",
    "    :age_group: 'group'/None кодировать ли возвраст\n",
    "    :norm: (Bool) нормализовать ли данные при CounterEncoding\n",
    "    \"\"\"\n",
    "    user_ = user.copy().drop(drop_col, axis=1) #убираю колонки дропа\n",
    "    # Новый столбец с категориями возраста\n",
    "    bins = [0, 18, 30, 60, 120]\n",
    "    \n",
    "    if 'age' not in drop_col and (age_group == 'group'):\n",
    "        user_['age_group'] = pd.cut(user_['age'], bins, labels=['0-17', '18-30', '30-60', '60+'])\n",
    "        user_ = user_.drop(['age'] , axis =1 )\n",
    "    elif 'age' not in drop_col and (age_group == 'count'):\n",
    "        counter_age = CountEncoder(cols=['age'], \n",
    "                            return_df=True,\n",
    "                            normalize=True)\n",
    "        user_ = counter_age.fit_transform(user_)\n",
    "    elif 'age' not in drop_col and (age_group == 'none'):\n",
    "        user_ = user_\n",
    "    \n",
    "    #учу CounterEncoder_User\n",
    "    \n",
    "    if ('city' not in drop_col) and (count_city == True):\n",
    "        counter_user = CountEncoder(cols=['city'], \n",
    "                            return_df=True,\n",
    "                            normalize=norm)\n",
    "        user_ = counter_user.fit_transform(user_)\n",
    "        \n",
    "    if ('country' not in drop_col) and (count_country == True):\n",
    "        counter_country = CountEncoder(cols=['country'], \n",
    "                            return_df=True,\n",
    "                            normalize=norm)\n",
    "        user_ = counter_country.fit_transform(user_)\n",
    "        \n",
    "    \n",
    "    \n",
    "\n",
    "    #OHE_User\n",
    "    for col in ohe_col:\n",
    "        one_hot = pd.get_dummies(user_[col], prefix=col, drop_first=True)\n",
    "        user_ = pd.concat((user_.drop(col, axis=1), one_hot), axis=1)\n",
    "    \n",
    "    \n",
    "    return user_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2aa54be",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_post(post, n_pca = 20, drop = True, ohe = True,lemma =True):\n",
    "    \"\"\"\n",
    "    Функция получает на вход таблицу пост post.\n",
    "    Опционально проводит OneHotEncoding типов постов,\n",
    "    Лемматизацию текстов, Tf-Idf и накладывает на полученые вектора  PCA\n",
    "    \n",
    "    :n_pca: кол-во изерений в новом пространстве, если 0 не проводит pca b tf-idf\n",
    "    :drop: = True/False дропать ли колонку текст\n",
    "    :ohe: = True/False проводить ли  OneHotEncoding колонки topic\n",
    "    :lemma: =True/False проводить ли лемматизацию\n",
    "       \n",
    "    \"\"\"\n",
    "    post_ = post.copy()\n",
    "    wnl = WordNetLemmatizer()\n",
    "    \n",
    "    if lemma == True:\n",
    "        def preprocessing(line, token=wnl):\n",
    "            line = line.lower()\n",
    "            line = re.sub(r\"[{}]\".format(string.punctuation), \" \", line)\n",
    "            line = line.replace('\\n\\n', ' ').replace('\\n', ' ')\n",
    "            line = ' '.join([token.lemmatize(x) for x in line.split(' ')])\n",
    "            return line\n",
    "    else:\n",
    "        preprocessing = None\n",
    "\n",
    "    #учу OHE_Post\n",
    "    if ohe == True:\n",
    "        one_hot = pd.get_dummies(post_['topic'], prefix='topic', drop_first=True)\n",
    "        post_  = pd.concat((post_.drop(['topic'], axis=1), one_hot), axis=1)\n",
    "        post_transformd = post_\n",
    "    elif ohe == False:\n",
    "        post_transformd = post_.drop(['topic'],axis =1 )\n",
    "    \n",
    "    if n_pca > 0 :\n",
    "        #провожу tf-idf для Post\n",
    "    \n",
    "        tf = TfidfVectorizer(stop_words='english',\n",
    "                             preprocessor=preprocessing, \n",
    "                             min_df = 5) #создаю экземпляр класса\n",
    "        tf_idf_ = tf.fit_transform(post_['text'])#учу класс\n",
    "        tf_idf_ = tf_idf_.toarray() - tf_idf_.mean() #центрируем данные\n",
    "\n",
    "        list_col_pca = [f\"PCA_{nn}\" for nn in range(1,n_pca + 1)] \n",
    "        #ПРовожу PCA для User\n",
    "        pca = PCA(n_components=n_pca,random_state = 74)\n",
    "        #создаю экземплря PCA\n",
    "        PCA_dataset = pca.fit_transform(tf_idf_) #провожу PCA \n",
    "        PCA_dataset = pd.DataFrame(PCA_dataset, columns=list_col_pca,index=post.index)\n",
    "        #Трансформирую Post\n",
    "    \n",
    "        post_transformd = pd.concat((post_transformd, PCA_dataset), axis=1)\n",
    "        if drop == True:\n",
    "            post_transformd = post_transformd.drop(['text'],axis=1) \n",
    "            \n",
    "    \n",
    "    else:\n",
    "        if drop == True:\n",
    "            post_transformd = post_transformd.drop(['text'],axis=1)\n",
    "        \n",
    "    return post_transformd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cc570b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_col = []\n",
    "ohe_col=['os','source']#\n",
    "ohe_topic = True # КОДИРУЕМ ЛИ TOPIC\n",
    "count_city = True #кодируем ли счетчиком city\n",
    "count_country = True #кодируем ли country\n",
    "age_group = 'none' #кодируем ли ваозвраст в группы\n",
    "norm = True # прводим ли нормализацию\n",
    "\n",
    "user_transformd_= transform_user_with_drop_fich(user,\n",
    "                                                drop_col = drop_col,\n",
    "                                                ohe_col=ohe_col, \n",
    "                                                count_city = count_city, \n",
    "                                                count_country = count_country, \n",
    "                                                age_group = age_group, \n",
    "                                                norm = norm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b6d23813",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_transformd_ = transform_post(post, \n",
    "                                  2, \n",
    "                                  drop = False, \n",
    "                                  ohe = True,\n",
    "                                  lemma = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "840812df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_id</th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "      <th>topic_covid</th>\n",
       "      <th>topic_entertainment</th>\n",
       "      <th>topic_movie</th>\n",
       "      <th>topic_politics</th>\n",
       "      <th>topic_sport</th>\n",
       "      <th>topic_tech</th>\n",
       "      <th>PCA_1</th>\n",
       "      <th>PCA_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>UK economy facing major risks\\n\\nThe UK manufa...</td>\n",
       "      <td>business</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.014171</td>\n",
       "      <td>0.181408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Aids and climate top Davos agenda\\n\\nClimate c...</td>\n",
       "      <td>business</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.020236</td>\n",
       "      <td>0.196847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Asian quake hits European shares\\n\\nShares in ...</td>\n",
       "      <td>business</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.016894</td>\n",
       "      <td>0.139923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>India power shares jump on debut\\n\\nShares in ...</td>\n",
       "      <td>business</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.005688</td>\n",
       "      <td>0.150133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Lacroix label bought by US firm\\n\\nLuxury good...</td>\n",
       "      <td>business</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.011384</td>\n",
       "      <td>0.116462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7018</th>\n",
       "      <td>7315</td>\n",
       "      <td>OK, I would not normally watch a Farrelly brot...</td>\n",
       "      <td>movie</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.140394</td>\n",
       "      <td>-0.155916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7019</th>\n",
       "      <td>7316</td>\n",
       "      <td>I give this movie 2 stars purely because of it...</td>\n",
       "      <td>movie</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.121802</td>\n",
       "      <td>-0.129093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7020</th>\n",
       "      <td>7317</td>\n",
       "      <td>I cant believe this film was allowed to be mad...</td>\n",
       "      <td>movie</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.090928</td>\n",
       "      <td>-0.071366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7021</th>\n",
       "      <td>7318</td>\n",
       "      <td>The version I saw of this film was the Blockbu...</td>\n",
       "      <td>movie</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.075142</td>\n",
       "      <td>-0.034659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7022</th>\n",
       "      <td>7319</td>\n",
       "      <td>Piece of subtle art. Maybe a masterpiece. Doub...</td>\n",
       "      <td>movie</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.051829</td>\n",
       "      <td>-0.030471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7023 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      post_id                                               text     topic  \\\n",
       "0           1  UK economy facing major risks\\n\\nThe UK manufa...  business   \n",
       "1           2  Aids and climate top Davos agenda\\n\\nClimate c...  business   \n",
       "2           3  Asian quake hits European shares\\n\\nShares in ...  business   \n",
       "3           4  India power shares jump on debut\\n\\nShares in ...  business   \n",
       "4           5  Lacroix label bought by US firm\\n\\nLuxury good...  business   \n",
       "...       ...                                                ...       ...   \n",
       "7018     7315  OK, I would not normally watch a Farrelly brot...     movie   \n",
       "7019     7316  I give this movie 2 stars purely because of it...     movie   \n",
       "7020     7317  I cant believe this film was allowed to be mad...     movie   \n",
       "7021     7318  The version I saw of this film was the Blockbu...     movie   \n",
       "7022     7319  Piece of subtle art. Maybe a masterpiece. Doub...     movie   \n",
       "\n",
       "      topic_covid  topic_entertainment  topic_movie  topic_politics  \\\n",
       "0               0                    0            0               0   \n",
       "1               0                    0            0               0   \n",
       "2               0                    0            0               0   \n",
       "3               0                    0            0               0   \n",
       "4               0                    0            0               0   \n",
       "...           ...                  ...          ...             ...   \n",
       "7018            0                    0            1               0   \n",
       "7019            0                    0            1               0   \n",
       "7020            0                    0            1               0   \n",
       "7021            0                    0            1               0   \n",
       "7022            0                    0            1               0   \n",
       "\n",
       "      topic_sport  topic_tech     PCA_1     PCA_2  \n",
       "0               0           0 -0.014171  0.181408  \n",
       "1               0           0 -0.020236  0.196847  \n",
       "2               0           0 -0.016894  0.139923  \n",
       "3               0           0 -0.005688  0.150133  \n",
       "4               0           0 -0.011384  0.116462  \n",
       "...           ...         ...       ...       ...  \n",
       "7018            0           0 -0.140394 -0.155916  \n",
       "7019            0           0 -0.121802 -0.129093  \n",
       "7020            0           0 -0.090928 -0.071366  \n",
       "7021            0           0 -0.075142 -0.034659  \n",
       "7022            0           0 -0.051829 -0.030471  \n",
       "\n",
       "[7023 rows x 11 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "post_transformd_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba4dd9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = create_engine(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "46fd40eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "205"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#записал эту таблицу\n",
    "user_transformd_.to_sql('shestov_user_lesson_22_v2', con=engine) # записываем таблицу\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "37d77265",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#записал эту таблицу\n",
    "post_transformd_.to_sql('shestov_post_lesson_22_v1.1', con=engine) # записываем таблицу"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
